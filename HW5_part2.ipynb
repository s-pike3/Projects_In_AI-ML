{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlczuLE/h6FNP+PrgRhr0D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-pike3/Projects_In_AI-ML/blob/main/HW5_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "Projects in AI & ML HW5 Part 2 \\\\\n",
        "Sarah Pike"
      ],
      "metadata": {
        "id": "b6NFsNDJKn2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Link to the dataset: https://www.kaggle.com/datasets/alessiocorrado99/animals10"
      ],
      "metadata": {
        "id": "Ga5Yvp3-68Po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import tree\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.autograd import Variable\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "!pip install torcheval\n",
        "from torcheval.metrics import MulticlassAccuracy"
      ],
      "metadata": {
        "id": "NzKgZZ7N4POP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36569eab-68ff-415c-e0f9-7d3700fba580"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torcheval\n",
            "  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torcheval) (4.12.2)\n",
            "Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torcheval\n",
            "Successfully installed torcheval-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "id": "7bng34bVEfV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"alessiocorrado99/animals10\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_uif4BEZRpw",
        "outputId": "f8e44c7d-ba6d-4a80-ccd0-d04645de5cb8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/alessiocorrado99/animals10?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 586M/586M [00:07<00:00, 82.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/alessiocorrado99/animals10/versions/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "data_dir = \"/root/.cache/kagglehub/datasets/alessiocorrado99/animals10/versions/2/raw-img\"\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Resize images to a uniform size\n",
        "    transforms.ToTensor()          # Convert images to tensors\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "dataset = datasets.ImageFolder(data_dir, transform=transform)"
      ],
      "metadata": {
        "id": "al_skYAJrwzb"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-Val-Test Split"
      ],
      "metadata": {
        "id": "mL320vvI0L9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "generator1 = torch.Generator().manual_seed(42)\n",
        "trainset,valset,testset = random_split(dataset, [int(len(dataset)*0.8)+1, int(len(dataset)*0.1)+1,int(len(dataset)*0.1)], generator=generator1)"
      ],
      "metadata": {
        "id": "iOdAd6lczdQ2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "valloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "nVRTr7C22RvQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VAE\n",
        "\n",
        "Implementation from:  https://medium.com/@rekalantar/variational-auto-encoder-vae-pytorch-tutorial-dce2d2fe0f5f"
      ],
      "metadata": {
        "id": "KpwGpjO7Hww1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From https://medium.com/@rekalantar/variational-auto-encoder-vae-pytorch-tutorial-dce2d2fe0f5f\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim=3*1024, hidden_dim=512, latent_dim=256):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.mean = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.var = nn.Linear (hidden_dim, latent_dim)\n",
        "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
        "        self.training = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(\"enc\")\n",
        "        x = self.LeakyReLU(self.linear1(x))\n",
        "        x = self.LeakyReLU(self.linear2(x))\n",
        "\n",
        "        mean = self.mean(x)\n",
        "        log_var = self.var(x)\n",
        "        return mean, log_var"
      ],
      "metadata": {
        "id": "IGhhJOe6Kjrm"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From https://medium.com/@rekalantar/variational-auto-encoder-vae-pytorch-tutorial-dce2d2fe0f5f\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, output_dim=3*1024, hidden_dim=512, latent_dim=256):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.linear2 = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.linear1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.output = nn.Linear(hidden_dim, output_dim)\n",
        "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(\"dec\")\n",
        "        x = self.LeakyReLU(self.linear2(x))\n",
        "        #print(\"dec2\")\n",
        "        x = self.LeakyReLU(self.linear1(x))\n",
        "\n",
        "        x_hat = torch.sigmoid(self.output(x))\n",
        "        return x_hat"
      ],
      "metadata": {
        "id": "OGx5HonuKkkO"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From https://medium.com/@rekalantar/variational-auto-encoder-vae-pytorch-tutorial-dce2d2fe0f5f\n",
        "class VAE(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim=3*1024, hidden_dim=400, latent_dim=200):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        # encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(hidden_dim, latent_dim),\n",
        "            nn.LeakyReLU(0.2)\n",
        "            )\n",
        "\n",
        "        # latent mean and variance\n",
        "        self.mean_layer = nn.Linear(latent_dim, 2)\n",
        "        self.logvar_layer = nn.Linear(latent_dim, 2)\n",
        "\n",
        "        # decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(2, latent_dim),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(latent_dim, hidden_dim),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(hidden_dim, input_dim),\n",
        "            nn.Sigmoid()\n",
        "            )\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.encoder(x)\n",
        "        mean, logvar = self.mean_layer(x), self.logvar_layer(x)\n",
        "        return mean, logvar\n",
        "\n",
        "    def reparameterization(self, mean, var):\n",
        "        epsilon = torch.randn_like(var)\n",
        "        z = mean + var*epsilon\n",
        "        return z\n",
        "\n",
        "    def decode(self, x):\n",
        "        return self.decoder(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean, logvar = self.encode(x)\n",
        "        z = self.reparameterization(mean, logvar)\n",
        "        x_hat = self.decode(z)\n",
        "        return x_hat, mean, logvar\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean, log_var = self.encode(x)\n",
        "        z = self.reparameterization(mean, torch.exp(0.5 * log_var))\n",
        "        x_hat = self.decode(z)\n",
        "        return x_hat, mean, log_var"
      ],
      "metadata": {
        "id": "maVMuMKyKpz_"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VAE()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "y1RdbXeNI0eX"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From https://medium.com/@rekalantar/variational-auto-encoder-vae-pytorch-tutorial-dce2d2fe0f5f\n",
        "def loss_function(x, x_hat, mean, log_var):\n",
        "    #print(x)\n",
        "    reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')\n",
        "    KLD = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
        "\n",
        "    return reproduction_loss + KLD"
      ],
      "metadata": {
        "id": "0SV-nJZlJLGi"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training"
      ],
      "metadata": {
        "id": "2Y3eNTOZIYRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, epochs,  x_dim=1024*3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        overall_loss = 0\n",
        "        for batch_idx, (x, _) in enumerate(trainloader):\n",
        "            x = x.view(batch_size, x_dim)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            x_hat, mean, log_var = model(x)\n",
        "            loss = loss_function(x, x_hat, mean, log_var)\n",
        "\n",
        "            overall_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(\"\\tEpoch\", epoch + 1, \"\\tAverage Loss: \", overall_loss/(batch_idx*batch_size))\n",
        "    return overall_loss"
      ],
      "metadata": {
        "id": "3lRLRbk-BhW9"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, optimizer, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Gbg80PT8LQlr",
        "outputId": "e53a4ae2-314d-482b-e4ec-06e85088a065"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tEpoch 1 \tAverage Loss:  1926.0519721935302\n",
            "\tEpoch 2 \tAverage Loss:  1925.6331074371747\n",
            "\tEpoch 3 \tAverage Loss:  1924.9428492638278\n",
            "\tEpoch 4 \tAverage Loss:  1924.4748041650746\n",
            "\tEpoch 5 \tAverage Loss:  1924.0023967668578\n",
            "\tEpoch 6 \tAverage Loss:  1923.5331346033\n",
            "\tEpoch 7 \tAverage Loss:  1923.3150599781775\n",
            "\tEpoch 8 \tAverage Loss:  1922.9794918143389\n",
            "\tEpoch 9 \tAverage Loss:  1922.335064582985\n",
            "\tEpoch 10 \tAverage Loss:  1921.9063561643222\n",
            "\tEpoch 11 \tAverage Loss:  1921.6294973371228\n",
            "\tEpoch 12 \tAverage Loss:  1921.5154256387025\n",
            "\tEpoch 13 \tAverage Loss:  1921.3740296413027\n",
            "\tEpoch 14 \tAverage Loss:  1921.429925670048\n",
            "\tEpoch 15 \tAverage Loss:  1921.5504646694837\n",
            "\tEpoch 16 \tAverage Loss:  1920.4853374290249\n",
            "\tEpoch 17 \tAverage Loss:  1920.4179460338203\n",
            "\tEpoch 18 \tAverage Loss:  1920.267755189924\n",
            "\tEpoch 19 \tAverage Loss:  1920.422708921684\n",
            "\tEpoch 20 \tAverage Loss:  1920.2485540008836\n",
            "\tEpoch 21 \tAverage Loss:  1919.821285190954\n",
            "\tEpoch 22 \tAverage Loss:  1920.4793280899228\n",
            "\tEpoch 23 \tAverage Loss:  1920.213016007117\n",
            "\tEpoch 24 \tAverage Loss:  1919.614530033495\n",
            "\tEpoch 25 \tAverage Loss:  1920.552684837869\n",
            "\tEpoch 26 \tAverage Loss:  1919.244537901596\n",
            "\tEpoch 27 \tAverage Loss:  1919.5165266970619\n",
            "\tEpoch 28 \tAverage Loss:  1919.45568581779\n",
            "\tEpoch 29 \tAverage Loss:  1919.2710945616252\n",
            "\tEpoch 30 \tAverage Loss:  1918.9575924375924\n",
            "\tEpoch 31 \tAverage Loss:  1918.9992028346808\n",
            "\tEpoch 32 \tAverage Loss:  1919.144293732984\n",
            "\tEpoch 33 \tAverage Loss:  1919.240162028399\n",
            "\tEpoch 34 \tAverage Loss:  1918.4513159618152\n",
            "\tEpoch 35 \tAverage Loss:  1918.3497353168584\n",
            "\tEpoch 36 \tAverage Loss:  1918.3432684356492\n",
            "\tEpoch 37 \tAverage Loss:  1919.089319598643\n",
            "\tEpoch 38 \tAverage Loss:  1918.5857156557486\n",
            "\tEpoch 39 \tAverage Loss:  1918.2205632362468\n",
            "\tEpoch 40 \tAverage Loss:  1918.7355908520312\n",
            "\tEpoch 41 \tAverage Loss:  1918.561910172296\n",
            "\tEpoch 42 \tAverage Loss:  1917.8269214156387\n",
            "\tEpoch 43 \tAverage Loss:  1918.2874489982119\n",
            "\tEpoch 44 \tAverage Loss:  1917.3500536698898\n",
            "\tEpoch 45 \tAverage Loss:  1918.8237460948694\n",
            "\tEpoch 46 \tAverage Loss:  1917.6784942242132\n",
            "\tEpoch 47 \tAverage Loss:  1918.0490298185541\n",
            "\tEpoch 48 \tAverage Loss:  1918.2048007730405\n",
            "\tEpoch 49 \tAverage Loss:  1918.5284797455638\n",
            "\tEpoch 50 \tAverage Loss:  1917.772940076304\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40150494.2734375"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reconstruction"
      ],
      "metadata": {
        "id": "6UvgyP59IpJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Original image in reduced dimension\n",
        "image, label = dataset[15000]\n",
        "\n",
        "image_np = image.permute(1, 2, 0).numpy()\n",
        "\n",
        "# Display the image using Matplotlib\n",
        "plt.imshow(image_np)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "j0x3IYID8Hxr",
        "outputId": "b4c801e5-5c4e-4410-e9b2-43ae2fefaf3f"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_img = model(image.reshape(1,3*1024))"
      ],
      "metadata": {
        "id": "p1zOWPEX8a9s"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reconstructed image\n",
        "img = gen_img[0].detach().reshape(3)\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "t38bmSrA8tYK",
        "outputId": "10a9ea90-a89b-4061-c716-de58753647a8"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a609749ded0>"
            ]
          },
          "metadata": {},
          "execution_count": 127
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GAN\n",
        "Implementation from: https://medium.com/@theprogramminggeek/generating-new-realities-crafting-a-simple-gan-with-pytorch-fc312f57a12d"
      ],
      "metadata": {
        "id": "v8WCwdv8Trm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From https://medium.com/@theprogramminggeek/generating-new-realities-crafting-a-simple-gan-with-pytorch-fc312f57a12d\n",
        "latent_dim = 100  # Size of the random noise vector\n",
        "\n",
        "# Define the Generator's architecture\n",
        "G = nn.Sequential(\n",
        "    nn.Linear(latent_dim, 256),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(256, 512),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(512, 1024),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(1024, 32*32*3),\n",
        "    nn.Tanh()\n",
        ")"
      ],
      "metadata": {
        "id": "85z3iirbu2n-"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From https://medium.com/@theprogramminggeek/generating-new-realities-crafting-a-simple-gan-with-pytorch-fc312f57a12d\n",
        "# Define the Discriminator's architecture\n",
        "D = nn.Sequential(\n",
        "    nn.Linear(32*32*3, 1024),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(1024, 512),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(512, 256),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(256, 1),\n",
        "    nn.Sigmoid()\n",
        ")"
      ],
      "metadata": {
        "id": "xv9hFKoqu7FX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Optimizers\n",
        "G_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "D_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))"
      ],
      "metadata": {
        "id": "mVwvc6B0u9fw"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # From https://medium.com/@theprogramminggeek/generating-new-realities-crafting-a-simple-gan-with-pytorch-fc312f57a12d\n",
        "import torch.autograd as autograd\n",
        "\n",
        "# Number of epochs\n",
        "num_epochs = 15\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, _) in enumerate(trainloader):\n",
        "        # Flatten the images for the Discriminator\n",
        "        images = images.view(images.size(0), -1)\n",
        "\n",
        "        # Real labels are 1, fake labels are 0\n",
        "        real_labels = torch.ones(images.size(0), 1)\n",
        "        fake_labels = torch.zeros(images.size(0), 1)\n",
        "\n",
        "\n",
        "        # Train the Discriminator\n",
        "        D_optimizer.zero_grad()\n",
        "\n",
        "        # Compute BCELoss using real images\n",
        "        outputs = D(images)\n",
        "        D_loss_real = criterion(outputs, real_labels)\n",
        "        real_score = outputs\n",
        "\n",
        "        # Generate fake images\n",
        "        z = torch.randn(images.size(0), latent_dim)\n",
        "        fake_images = G(z)\n",
        "\n",
        "        # Compute BCELoss using fake images\n",
        "        outputs = D(fake_images.detach())\n",
        "        D_loss_fake = criterion(outputs, fake_labels)\n",
        "        fake_score = outputs\n",
        "\n",
        "        # Optimize the Discriminator\n",
        "        D_loss = D_loss_real + D_loss_fake\n",
        "        D_loss.backward()\n",
        "        D_optimizer.step()\n",
        "\n",
        "        # Train the Generator\n",
        "        G_optimizer.zero_grad()\n",
        "\n",
        "        # Generate fake images\n",
        "        z = torch.randn(images.size(0), latent_dim)\n",
        "        fake_images = G(z)\n",
        "\n",
        "        # Compute BCELoss using fake images, with reversed labels\n",
        "        outputs = D(fake_images)\n",
        "        G_loss = criterion(outputs, real_labels)\n",
        "\n",
        "        # Optimize the Generator\n",
        "        G_loss.backward()\n",
        "        G_optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], D_loss: {:.4f}, G_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}'\n",
        "                  .format(epoch+1, num_epochs, i+1, len(trainloader), D_loss.item(), G_loss.item(),\n",
        "                          real_score.mean().item(), fake_score.mean().item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WxLYZOc3vAwI",
        "outputId": "cfe5b4e1-07a2-4cb2-db90-306767a317ec"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/15], Step [100/2618], D_loss: 1.3270, G_loss: 0.7420, D(x): 0.48, D(G(z)): 0.45\n",
            "Epoch [1/15], Step [200/2618], D_loss: 1.3395, G_loss: 0.7996, D(x): 0.48, D(G(z)): 0.45\n",
            "Epoch [1/15], Step [300/2618], D_loss: 1.4247, G_loss: 0.6879, D(x): 0.51, D(G(z)): 0.53\n",
            "Epoch [1/15], Step [400/2618], D_loss: 1.3420, G_loss: 0.7607, D(x): 0.49, D(G(z)): 0.46\n",
            "Epoch [1/15], Step [500/2618], D_loss: 1.4351, G_loss: 0.7477, D(x): 0.48, D(G(z)): 0.50\n",
            "Epoch [1/15], Step [600/2618], D_loss: 1.2792, G_loss: 0.7031, D(x): 0.56, D(G(z)): 0.51\n",
            "Epoch [1/15], Step [700/2618], D_loss: 1.5169, G_loss: 0.6774, D(x): 0.48, D(G(z)): 0.54\n",
            "Epoch [1/15], Step [800/2618], D_loss: 1.4468, G_loss: 0.6710, D(x): 0.48, D(G(z)): 0.50\n",
            "Epoch [1/15], Step [900/2618], D_loss: 1.4607, G_loss: 0.7738, D(x): 0.47, D(G(z)): 0.50\n",
            "Epoch [1/15], Step [1000/2618], D_loss: 1.4402, G_loss: 0.5968, D(x): 0.55, D(G(z)): 0.57\n",
            "Epoch [1/15], Step [1100/2618], D_loss: 1.4238, G_loss: 0.7624, D(x): 0.46, D(G(z)): 0.47\n",
            "Epoch [1/15], Step [1200/2618], D_loss: 1.4507, G_loss: 0.7024, D(x): 0.48, D(G(z)): 0.51\n",
            "Epoch [1/15], Step [1300/2618], D_loss: 1.3738, G_loss: 0.7159, D(x): 0.50, D(G(z)): 0.49\n",
            "Epoch [1/15], Step [1400/2618], D_loss: 1.3745, G_loss: 0.7377, D(x): 0.48, D(G(z)): 0.47\n",
            "Epoch [1/15], Step [1500/2618], D_loss: 1.4169, G_loss: 0.7221, D(x): 0.48, D(G(z)): 0.49\n",
            "Epoch [1/15], Step [1600/2618], D_loss: 1.3815, G_loss: 0.6903, D(x): 0.50, D(G(z)): 0.50\n",
            "Epoch [1/15], Step [1700/2618], D_loss: 1.4107, G_loss: 0.7080, D(x): 0.47, D(G(z)): 0.48\n",
            "Epoch [1/15], Step [1800/2618], D_loss: 1.4310, G_loss: 0.6836, D(x): 0.50, D(G(z)): 0.52\n",
            "Epoch [1/15], Step [1900/2618], D_loss: 1.3953, G_loss: 0.7666, D(x): 0.49, D(G(z)): 0.50\n",
            "Epoch [1/15], Step [2000/2618], D_loss: 1.4529, G_loss: 0.5926, D(x): 0.47, D(G(z)): 0.50\n",
            "Epoch [1/15], Step [2100/2618], D_loss: 1.3568, G_loss: 0.6179, D(x): 0.55, D(G(z)): 0.53\n",
            "Epoch [1/15], Step [2200/2618], D_loss: 1.3445, G_loss: 0.6881, D(x): 0.52, D(G(z)): 0.50\n",
            "Epoch [1/15], Step [2300/2618], D_loss: 1.4042, G_loss: 0.7760, D(x): 0.46, D(G(z)): 0.46\n",
            "Epoch [1/15], Step [2400/2618], D_loss: 1.3528, G_loss: 0.7216, D(x): 0.48, D(G(z)): 0.46\n",
            "Epoch [1/15], Step [2500/2618], D_loss: 1.3856, G_loss: 0.6743, D(x): 0.51, D(G(z)): 0.51\n",
            "Epoch [1/15], Step [2600/2618], D_loss: 1.3959, G_loss: 0.6773, D(x): 0.51, D(G(z)): 0.51\n",
            "Epoch [2/15], Step [100/2618], D_loss: 1.3437, G_loss: 0.6536, D(x): 0.53, D(G(z)): 0.51\n",
            "Epoch [2/15], Step [200/2618], D_loss: 1.4041, G_loss: 0.7227, D(x): 0.49, D(G(z)): 0.50\n",
            "Epoch [2/15], Step [300/2618], D_loss: 1.3515, G_loss: 0.6873, D(x): 0.51, D(G(z)): 0.50\n",
            "Epoch [2/15], Step [400/2618], D_loss: 1.3650, G_loss: 0.6927, D(x): 0.50, D(G(z)): 0.49\n",
            "Epoch [2/15], Step [500/2618], D_loss: 1.4738, G_loss: 0.6353, D(x): 0.52, D(G(z)): 0.56\n",
            "Epoch [2/15], Step [600/2618], D_loss: 1.4005, G_loss: 0.7525, D(x): 0.55, D(G(z)): 0.55\n",
            "Epoch [2/15], Step [700/2618], D_loss: 1.4417, G_loss: 0.6291, D(x): 0.53, D(G(z)): 0.55\n",
            "Epoch [2/15], Step [800/2618], D_loss: 1.3879, G_loss: 0.7603, D(x): 0.46, D(G(z)): 0.46\n",
            "Epoch [2/15], Step [900/2618], D_loss: 1.3754, G_loss: 0.7038, D(x): 0.51, D(G(z)): 0.51\n",
            "Epoch [2/15], Step [1000/2618], D_loss: 1.3882, G_loss: 0.7357, D(x): 0.47, D(G(z)): 0.47\n",
            "Epoch [2/15], Step [1100/2618], D_loss: 1.3627, G_loss: 0.6891, D(x): 0.51, D(G(z)): 0.50\n",
            "Epoch [2/15], Step [1200/2618], D_loss: 1.3707, G_loss: 0.6767, D(x): 0.51, D(G(z)): 0.50\n",
            "Epoch [2/15], Step [1300/2618], D_loss: 1.3525, G_loss: 0.7885, D(x): 0.49, D(G(z)): 0.47\n",
            "Epoch [2/15], Step [1400/2618], D_loss: 1.3993, G_loss: 0.7268, D(x): 0.47, D(G(z)): 0.47\n",
            "Epoch [2/15], Step [1500/2618], D_loss: 1.3715, G_loss: 0.6425, D(x): 0.51, D(G(z)): 0.50\n",
            "Epoch [2/15], Step [1600/2618], D_loss: 1.4085, G_loss: 0.6652, D(x): 0.51, D(G(z)): 0.52\n",
            "Epoch [2/15], Step [1700/2618], D_loss: 1.4289, G_loss: 0.6966, D(x): 0.48, D(G(z)): 0.49\n",
            "Epoch [2/15], Step [1800/2618], D_loss: 1.3311, G_loss: 0.6600, D(x): 0.54, D(G(z)): 0.51\n",
            "Epoch [2/15], Step [1900/2618], D_loss: 1.4426, G_loss: 0.6122, D(x): 0.52, D(G(z)): 0.54\n",
            "Epoch [2/15], Step [2000/2618], D_loss: 1.3955, G_loss: 0.6443, D(x): 0.52, D(G(z)): 0.53\n",
            "Epoch [2/15], Step [2100/2618], D_loss: 1.3367, G_loss: 0.6045, D(x): 0.54, D(G(z)): 0.51\n",
            "Epoch [2/15], Step [2200/2618], D_loss: 1.3604, G_loss: 0.6753, D(x): 0.53, D(G(z)): 0.52\n",
            "Epoch [2/15], Step [2300/2618], D_loss: 1.4234, G_loss: 0.6554, D(x): 0.50, D(G(z)): 0.52\n",
            "Epoch [2/15], Step [2400/2618], D_loss: 1.3508, G_loss: 0.7256, D(x): 0.51, D(G(z)): 0.49\n",
            "Epoch [2/15], Step [2500/2618], D_loss: 1.3570, G_loss: 0.6602, D(x): 0.54, D(G(z)): 0.52\n",
            "Epoch [2/15], Step [2600/2618], D_loss: 1.4116, G_loss: 0.7254, D(x): 0.51, D(G(z)): 0.52\n",
            "Epoch [3/15], Step [100/2618], D_loss: 1.3611, G_loss: 0.7778, D(x): 0.50, D(G(z)): 0.48\n",
            "Epoch [3/15], Step [200/2618], D_loss: 1.4186, G_loss: 0.5954, D(x): 0.54, D(G(z)): 0.54\n",
            "Epoch [3/15], Step [300/2618], D_loss: 1.4051, G_loss: 0.7502, D(x): 0.45, D(G(z)): 0.46\n",
            "Epoch [3/15], Step [400/2618], D_loss: 1.4563, G_loss: 0.6999, D(x): 0.49, D(G(z)): 0.51\n",
            "Epoch [3/15], Step [500/2618], D_loss: 1.3636, G_loss: 0.6452, D(x): 0.53, D(G(z)): 0.52\n",
            "Epoch [3/15], Step [600/2618], D_loss: 1.3883, G_loss: 0.7115, D(x): 0.49, D(G(z)): 0.49\n",
            "Epoch [3/15], Step [700/2618], D_loss: 1.4175, G_loss: 0.7350, D(x): 0.49, D(G(z)): 0.50\n",
            "Epoch [3/15], Step [800/2618], D_loss: 1.3650, G_loss: 0.7482, D(x): 0.47, D(G(z)): 0.46\n",
            "Epoch [3/15], Step [900/2618], D_loss: 1.3888, G_loss: 0.7038, D(x): 0.52, D(G(z)): 0.52\n",
            "Epoch [3/15], Step [1000/2618], D_loss: 1.3800, G_loss: 0.7157, D(x): 0.48, D(G(z)): 0.48\n",
            "Epoch [3/15], Step [1100/2618], D_loss: 1.4249, G_loss: 0.6821, D(x): 0.50, D(G(z)): 0.51\n",
            "Epoch [3/15], Step [1200/2618], D_loss: 1.3898, G_loss: 0.6750, D(x): 0.51, D(G(z)): 0.51\n",
            "Epoch [3/15], Step [1300/2618], D_loss: 1.4125, G_loss: 0.8170, D(x): 0.48, D(G(z)): 0.49\n",
            "Epoch [3/15], Step [1400/2618], D_loss: 1.2806, G_loss: 0.7012, D(x): 0.57, D(G(z)): 0.51\n",
            "Epoch [3/15], Step [1500/2618], D_loss: 1.3728, G_loss: 0.6792, D(x): 0.55, D(G(z)): 0.54\n",
            "Epoch [3/15], Step [1600/2618], D_loss: 1.3907, G_loss: 0.7774, D(x): 0.48, D(G(z)): 0.48\n",
            "Epoch [3/15], Step [1700/2618], D_loss: 1.2944, G_loss: 1.0536, D(x): 0.48, D(G(z)): 0.43\n",
            "Epoch [3/15], Step [1800/2618], D_loss: 1.3723, G_loss: 0.7435, D(x): 0.49, D(G(z)): 0.48\n",
            "Epoch [3/15], Step [1900/2618], D_loss: 1.4110, G_loss: 0.6305, D(x): 0.53, D(G(z)): 0.54\n",
            "Epoch [3/15], Step [2000/2618], D_loss: 1.3787, G_loss: 0.6944, D(x): 0.50, D(G(z)): 0.50\n",
            "Epoch [3/15], Step [2100/2618], D_loss: 1.4341, G_loss: 0.5898, D(x): 0.51, D(G(z)): 0.52\n",
            "Epoch [3/15], Step [2200/2618], D_loss: 1.2661, G_loss: 0.9083, D(x): 0.47, D(G(z)): 0.38\n",
            "Epoch [3/15], Step [2300/2618], D_loss: 1.3580, G_loss: 0.6604, D(x): 0.52, D(G(z)): 0.50\n",
            "Epoch [3/15], Step [2400/2618], D_loss: 1.3503, G_loss: 0.8052, D(x): 0.47, D(G(z)): 0.45\n",
            "Epoch [3/15], Step [2500/2618], D_loss: 1.3376, G_loss: 0.6771, D(x): 0.53, D(G(z)): 0.50\n",
            "Epoch [3/15], Step [2600/2618], D_loss: 1.3902, G_loss: 0.6022, D(x): 0.55, D(G(z)): 0.54\n",
            "Epoch [4/15], Step [100/2618], D_loss: 1.3908, G_loss: 0.6802, D(x): 0.50, D(G(z)): 0.50\n",
            "Epoch [4/15], Step [200/2618], D_loss: 1.3677, G_loss: 0.6535, D(x): 0.54, D(G(z)): 0.53\n",
            "Epoch [4/15], Step [300/2618], D_loss: 1.3787, G_loss: 0.7034, D(x): 0.50, D(G(z)): 0.49\n",
            "Epoch [4/15], Step [400/2618], D_loss: 1.4608, G_loss: 0.6966, D(x): 0.47, D(G(z)): 0.50\n",
            "Epoch [4/15], Step [500/2618], D_loss: 1.4396, G_loss: 0.7121, D(x): 0.50, D(G(z)): 0.52\n",
            "Epoch [4/15], Step [600/2618], D_loss: 1.4146, G_loss: 0.6847, D(x): 0.48, D(G(z)): 0.50\n",
            "Epoch [4/15], Step [700/2618], D_loss: 1.3964, G_loss: 0.6457, D(x): 0.53, D(G(z)): 0.53\n",
            "Epoch [4/15], Step [800/2618], D_loss: 1.3663, G_loss: 0.6386, D(x): 0.53, D(G(z)): 0.51\n",
            "Epoch [4/15], Step [900/2618], D_loss: 1.3718, G_loss: 0.6647, D(x): 0.52, D(G(z)): 0.51\n",
            "Epoch [4/15], Step [1000/2618], D_loss: 1.3947, G_loss: 0.6690, D(x): 0.52, D(G(z)): 0.52\n",
            "Epoch [4/15], Step [1100/2618], D_loss: 1.3569, G_loss: 0.6889, D(x): 0.52, D(G(z)): 0.51\n",
            "Epoch [4/15], Step [1200/2618], D_loss: 1.3792, G_loss: 0.7137, D(x): 0.52, D(G(z)): 0.51\n",
            "Epoch [4/15], Step [1300/2618], D_loss: 1.3635, G_loss: 0.6836, D(x): 0.52, D(G(z)): 0.51\n",
            "Epoch [4/15], Step [1400/2618], D_loss: 1.3994, G_loss: 0.7315, D(x): 0.49, D(G(z)): 0.50\n",
            "Epoch [4/15], Step [1500/2618], D_loss: 1.3766, G_loss: 0.6342, D(x): 0.54, D(G(z)): 0.53\n",
            "Epoch [4/15], Step [1600/2618], D_loss: 1.3540, G_loss: 0.7153, D(x): 0.51, D(G(z)): 0.49\n",
            "Epoch [4/15], Step [1700/2618], D_loss: 1.3295, G_loss: 0.5981, D(x): 0.60, D(G(z)): 0.55\n",
            "Epoch [4/15], Step [1800/2618], D_loss: 1.3435, G_loss: 0.6457, D(x): 0.54, D(G(z)): 0.51\n",
            "Epoch [4/15], Step [1900/2618], D_loss: 1.4115, G_loss: 0.6658, D(x): 0.50, D(G(z)): 0.51\n",
            "Epoch [4/15], Step [2000/2618], D_loss: 1.4254, G_loss: 0.6923, D(x): 0.48, D(G(z)): 0.49\n",
            "Epoch [4/15], Step [2100/2618], D_loss: 1.4236, G_loss: 0.6383, D(x): 0.51, D(G(z)): 0.53\n",
            "Epoch [4/15], Step [2200/2618], D_loss: 1.4319, G_loss: 0.6491, D(x): 0.51, D(G(z)): 0.53\n",
            "Epoch [4/15], Step [2300/2618], D_loss: 1.4237, G_loss: 0.6409, D(x): 0.53, D(G(z)): 0.54\n",
            "Epoch [4/15], Step [2400/2618], D_loss: 1.4319, G_loss: 0.6603, D(x): 0.54, D(G(z)): 0.55\n",
            "Epoch [4/15], Step [2500/2618], D_loss: 1.3780, G_loss: 0.6110, D(x): 0.53, D(G(z)): 0.52\n",
            "Epoch [4/15], Step [2600/2618], D_loss: 1.4127, G_loss: 0.7195, D(x): 0.49, D(G(z)): 0.50\n",
            "Epoch [5/15], Step [100/2618], D_loss: 1.3928, G_loss: 0.7847, D(x): 0.48, D(G(z)): 0.48\n",
            "Epoch [5/15], Step [200/2618], D_loss: 1.3603, G_loss: 0.7524, D(x): 0.49, D(G(z)): 0.48\n",
            "Epoch [5/15], Step [300/2618], D_loss: 1.4037, G_loss: 0.7218, D(x): 0.49, D(G(z)): 0.50\n",
            "Epoch [5/15], Step [400/2618], D_loss: 1.3928, G_loss: 0.6343, D(x): 0.53, D(G(z)): 0.53\n",
            "Epoch [5/15], Step [500/2618], D_loss: 1.3747, G_loss: 0.7609, D(x): 0.48, D(G(z)): 0.47\n",
            "Epoch [5/15], Step [600/2618], D_loss: 1.3941, G_loss: 0.7439, D(x): 0.48, D(G(z)): 0.48\n",
            "Epoch [5/15], Step [700/2618], D_loss: 1.3796, G_loss: 0.6793, D(x): 0.51, D(G(z)): 0.51\n",
            "Epoch [5/15], Step [800/2618], D_loss: 1.3761, G_loss: 0.6696, D(x): 0.51, D(G(z)): 0.51\n",
            "Epoch [5/15], Step [900/2618], D_loss: 1.3621, G_loss: 0.6745, D(x): 0.51, D(G(z)): 0.49\n",
            "Epoch [5/15], Step [1000/2618], D_loss: 1.4008, G_loss: 0.6404, D(x): 0.49, D(G(z)): 0.50\n",
            "Epoch [5/15], Step [1100/2618], D_loss: 1.4315, G_loss: 0.6773, D(x): 0.47, D(G(z)): 0.49\n",
            "Epoch [5/15], Step [1200/2618], D_loss: 1.4078, G_loss: 0.7164, D(x): 0.49, D(G(z)): 0.50\n",
            "Epoch [5/15], Step [1300/2618], D_loss: 1.3744, G_loss: 0.6134, D(x): 0.51, D(G(z)): 0.50\n",
            "Epoch [5/15], Step [1400/2618], D_loss: 1.3779, G_loss: 0.7140, D(x): 0.50, D(G(z)): 0.49\n",
            "Epoch [5/15], Step [1500/2618], D_loss: 1.3637, G_loss: 0.6960, D(x): 0.49, D(G(z)): 0.48\n",
            "Epoch [5/15], Step [1600/2618], D_loss: 1.4096, G_loss: 0.6935, D(x): 0.50, D(G(z)): 0.51\n",
            "Epoch [5/15], Step [1700/2618], D_loss: 1.3848, G_loss: 0.7090, D(x): 0.47, D(G(z)): 0.47\n",
            "Epoch [5/15], Step [1800/2618], D_loss: 1.4061, G_loss: 0.6417, D(x): 0.51, D(G(z)): 0.52\n",
            "Epoch [5/15], Step [1900/2618], D_loss: 1.4168, G_loss: 0.7696, D(x): 0.48, D(G(z)): 0.50\n",
            "Epoch [5/15], Step [2000/2618], D_loss: 1.3605, G_loss: 0.8016, D(x): 0.47, D(G(z)): 0.45\n",
            "Epoch [5/15], Step [2100/2618], D_loss: 1.5368, G_loss: 0.7722, D(x): 0.43, D(G(z)): 0.49\n",
            "Epoch [5/15], Step [2200/2618], D_loss: 1.3717, G_loss: 0.6177, D(x): 0.50, D(G(z)): 0.49\n",
            "Epoch [5/15], Step [2300/2618], D_loss: 1.4091, G_loss: 0.7307, D(x): 0.47, D(G(z)): 0.48\n",
            "Epoch [5/15], Step [2400/2618], D_loss: 1.3933, G_loss: 0.6676, D(x): 0.48, D(G(z)): 0.48\n",
            "Epoch [5/15], Step [2500/2618], D_loss: 1.4207, G_loss: 0.7146, D(x): 0.51, D(G(z)): 0.52\n",
            "Epoch [5/15], Step [2600/2618], D_loss: 1.4041, G_loss: 0.7267, D(x): 0.49, D(G(z)): 0.50\n",
            "Epoch [6/15], Step [100/2618], D_loss: 1.3424, G_loss: 0.7782, D(x): 0.50, D(G(z)): 0.47\n",
            "Epoch [6/15], Step [200/2618], D_loss: 1.4259, G_loss: 0.6502, D(x): 0.49, D(G(z)): 0.50\n",
            "Epoch [6/15], Step [300/2618], D_loss: 1.3794, G_loss: 0.6941, D(x): 0.50, D(G(z)): 0.50\n",
            "Epoch [6/15], Step [400/2618], D_loss: 1.2885, G_loss: 0.7546, D(x): 0.50, D(G(z)): 0.44\n",
            "Epoch [6/15], Step [500/2618], D_loss: 1.3945, G_loss: 0.7077, D(x): 0.50, D(G(z)): 0.50\n",
            "Epoch [6/15], Step [600/2618], D_loss: 1.3688, G_loss: 0.6634, D(x): 0.50, D(G(z)): 0.49\n",
            "Epoch [6/15], Step [700/2618], D_loss: 1.3211, G_loss: 0.8009, D(x): 0.50, D(G(z)): 0.46\n",
            "Epoch [6/15], Step [800/2618], D_loss: 1.3458, G_loss: 0.7074, D(x): 0.51, D(G(z)): 0.49\n",
            "Epoch [6/15], Step [900/2618], D_loss: 1.3295, G_loss: 0.7357, D(x): 0.54, D(G(z)): 0.51\n",
            "Epoch [6/15], Step [1000/2618], D_loss: 1.4207, G_loss: 0.7815, D(x): 0.48, D(G(z)): 0.49\n",
            "Epoch [6/15], Step [1100/2618], D_loss: 1.3580, G_loss: 0.7865, D(x): 0.48, D(G(z)): 0.47\n",
            "Epoch [6/15], Step [1200/2618], D_loss: 1.3954, G_loss: 0.6416, D(x): 0.52, D(G(z)): 0.52\n",
            "Epoch [6/15], Step [1300/2618], D_loss: 1.3700, G_loss: 0.6302, D(x): 0.48, D(G(z)): 0.46\n",
            "Epoch [6/15], Step [1400/2618], D_loss: 1.3453, G_loss: 0.6686, D(x): 0.53, D(G(z)): 0.50\n",
            "Epoch [6/15], Step [1500/2618], D_loss: 1.4016, G_loss: 0.7582, D(x): 0.43, D(G(z)): 0.43\n",
            "Epoch [6/15], Step [1600/2618], D_loss: 1.3910, G_loss: 0.7033, D(x): 0.50, D(G(z)): 0.50\n",
            "Epoch [6/15], Step [1700/2618], D_loss: 1.3565, G_loss: 0.6597, D(x): 0.56, D(G(z)): 0.54\n",
            "Epoch [6/15], Step [1800/2618], D_loss: 1.3893, G_loss: 0.6614, D(x): 0.51, D(G(z)): 0.51\n",
            "Epoch [6/15], Step [1900/2618], D_loss: 1.3956, G_loss: 0.6789, D(x): 0.52, D(G(z)): 0.52\n",
            "Epoch [6/15], Step [2000/2618], D_loss: 1.4523, G_loss: 0.7496, D(x): 0.46, D(G(z)): 0.49\n",
            "Epoch [6/15], Step [2100/2618], D_loss: 1.4036, G_loss: 0.6984, D(x): 0.47, D(G(z)): 0.48\n",
            "Epoch [6/15], Step [2200/2618], D_loss: 1.4976, G_loss: 0.7345, D(x): 0.46, D(G(z)): 0.51\n",
            "Epoch [6/15], Step [2300/2618], D_loss: 1.4125, G_loss: 0.7314, D(x): 0.53, D(G(z)): 0.54\n",
            "Epoch [6/15], Step [2400/2618], D_loss: 1.4376, G_loss: 0.7296, D(x): 0.48, D(G(z)): 0.50\n",
            "Epoch [6/15], Step [2500/2618], D_loss: 1.3959, G_loss: 0.6146, D(x): 0.52, D(G(z)): 0.52\n",
            "Epoch [6/15], Step [2600/2618], D_loss: 1.3969, G_loss: 0.7028, D(x): 0.49, D(G(z)): 0.50\n",
            "Epoch [7/15], Step [100/2618], D_loss: 1.3548, G_loss: 0.7187, D(x): 0.50, D(G(z)): 0.48\n",
            "Epoch [7/15], Step [200/2618], D_loss: 1.3021, G_loss: 0.7636, D(x): 0.50, D(G(z)): 0.45\n",
            "Epoch [7/15], Step [300/2618], D_loss: 1.4105, G_loss: 0.6910, D(x): 0.52, D(G(z)): 0.53\n",
            "Epoch [7/15], Step [400/2618], D_loss: 1.3868, G_loss: 0.7262, D(x): 0.49, D(G(z)): 0.48\n",
            "Epoch [7/15], Step [500/2618], D_loss: 1.4032, G_loss: 0.6522, D(x): 0.51, D(G(z)): 0.52\n",
            "Epoch [7/15], Step [600/2618], D_loss: 1.4139, G_loss: 0.6982, D(x): 0.51, D(G(z)): 0.53\n",
            "Epoch [7/15], Step [700/2618], D_loss: 1.3860, G_loss: 0.7198, D(x): 0.49, D(G(z)): 0.49\n",
            "Epoch [7/15], Step [800/2618], D_loss: 1.4401, G_loss: 0.6054, D(x): 0.52, D(G(z)): 0.54\n",
            "Epoch [7/15], Step [900/2618], D_loss: 1.3718, G_loss: 0.6893, D(x): 0.53, D(G(z)): 0.52\n",
            "Epoch [7/15], Step [1000/2618], D_loss: 1.3781, G_loss: 0.7061, D(x): 0.50, D(G(z)): 0.49\n",
            "Epoch [7/15], Step [1100/2618], D_loss: 1.4073, G_loss: 0.8068, D(x): 0.43, D(G(z)): 0.43\n",
            "Epoch [7/15], Step [1200/2618], D_loss: 1.4436, G_loss: 0.7495, D(x): 0.49, D(G(z)): 0.52\n",
            "Epoch [7/15], Step [1300/2618], D_loss: 1.4264, G_loss: 0.7089, D(x): 0.47, D(G(z)): 0.49\n",
            "Epoch [7/15], Step [1400/2618], D_loss: 1.3342, G_loss: 0.7040, D(x): 0.52, D(G(z)): 0.49\n",
            "Epoch [7/15], Step [1500/2618], D_loss: 1.3463, G_loss: 0.8303, D(x): 0.49, D(G(z)): 0.46\n",
            "Epoch [7/15], Step [1600/2618], D_loss: 1.4055, G_loss: 0.7864, D(x): 0.45, D(G(z)): 0.45\n",
            "Epoch [7/15], Step [1700/2618], D_loss: 1.4000, G_loss: 0.7973, D(x): 0.47, D(G(z)): 0.47\n",
            "Epoch [7/15], Step [1800/2618], D_loss: 1.4635, G_loss: 0.6997, D(x): 0.49, D(G(z)): 0.53\n",
            "Epoch [7/15], Step [1900/2618], D_loss: 1.4035, G_loss: 0.7525, D(x): 0.46, D(G(z)): 0.46\n",
            "Epoch [7/15], Step [2000/2618], D_loss: 1.3891, G_loss: 0.7440, D(x): 0.52, D(G(z)): 0.51\n",
            "Epoch [7/15], Step [2100/2618], D_loss: 1.4175, G_loss: 0.6756, D(x): 0.51, D(G(z)): 0.52\n",
            "Epoch [7/15], Step [2200/2618], D_loss: 1.3699, G_loss: 0.6582, D(x): 0.53, D(G(z)): 0.52\n",
            "Epoch [7/15], Step [2300/2618], D_loss: 1.4347, G_loss: 0.6938, D(x): 0.52, D(G(z)): 0.54\n",
            "Epoch [7/15], Step [2400/2618], D_loss: 1.4135, G_loss: 0.7916, D(x): 0.49, D(G(z)): 0.50\n",
            "Epoch [7/15], Step [2500/2618], D_loss: 1.3948, G_loss: 0.7945, D(x): 0.48, D(G(z)): 0.47\n",
            "Epoch [7/15], Step [2600/2618], D_loss: 1.3989, G_loss: 0.7335, D(x): 0.48, D(G(z)): 0.48\n",
            "Epoch [8/15], Step [100/2618], D_loss: 1.3461, G_loss: 0.7658, D(x): 0.48, D(G(z)): 0.46\n",
            "Epoch [8/15], Step [200/2618], D_loss: 1.3660, G_loss: 0.7777, D(x): 0.48, D(G(z)): 0.47\n",
            "Epoch [8/15], Step [300/2618], D_loss: 1.3950, G_loss: 0.7248, D(x): 0.48, D(G(z)): 0.49\n",
            "Epoch [8/15], Step [400/2618], D_loss: 1.4188, G_loss: 0.7554, D(x): 0.46, D(G(z)): 0.47\n",
            "Epoch [8/15], Step [500/2618], D_loss: 1.3970, G_loss: 0.7586, D(x): 0.47, D(G(z)): 0.47\n",
            "Epoch [8/15], Step [600/2618], D_loss: 1.3940, G_loss: 0.6685, D(x): 0.52, D(G(z)): 0.52\n",
            "Epoch [8/15], Step [700/2618], D_loss: 1.3373, G_loss: 0.7252, D(x): 0.51, D(G(z)): 0.48\n",
            "Epoch [8/15], Step [800/2618], D_loss: 1.4575, G_loss: 0.7859, D(x): 0.45, D(G(z)): 0.48\n",
            "Epoch [8/15], Step [900/2618], D_loss: 1.4493, G_loss: 0.6955, D(x): 0.50, D(G(z)): 0.52\n",
            "Epoch [8/15], Step [1000/2618], D_loss: 1.3721, G_loss: 0.6885, D(x): 0.53, D(G(z)): 0.52\n",
            "Epoch [8/15], Step [1100/2618], D_loss: 1.4767, G_loss: 0.7127, D(x): 0.48, D(G(z)): 0.52\n",
            "Epoch [8/15], Step [1200/2618], D_loss: 1.3281, G_loss: 0.7293, D(x): 0.51, D(G(z)): 0.48\n",
            "Epoch [8/15], Step [1300/2618], D_loss: 1.3598, G_loss: 0.7347, D(x): 0.51, D(G(z)): 0.50\n",
            "Epoch [8/15], Step [1400/2618], D_loss: 1.3924, G_loss: 0.7617, D(x): 0.48, D(G(z)): 0.48\n",
            "Epoch [8/15], Step [1500/2618], D_loss: 1.4256, G_loss: 0.6924, D(x): 0.50, D(G(z)): 0.51\n",
            "Epoch [8/15], Step [1600/2618], D_loss: 1.3672, G_loss: 0.8080, D(x): 0.45, D(G(z)): 0.43\n",
            "Epoch [8/15], Step [1700/2618], D_loss: 1.4188, G_loss: 0.6887, D(x): 0.48, D(G(z)): 0.49\n",
            "Epoch [8/15], Step [1800/2618], D_loss: 1.3824, G_loss: 0.7374, D(x): 0.51, D(G(z)): 0.51\n",
            "Epoch [8/15], Step [1900/2618], D_loss: 1.3675, G_loss: 0.7072, D(x): 0.51, D(G(z)): 0.50\n",
            "Epoch [8/15], Step [2000/2618], D_loss: 1.3075, G_loss: 0.6430, D(x): 0.56, D(G(z)): 0.52\n",
            "Epoch [8/15], Step [2100/2618], D_loss: 1.3776, G_loss: 0.6794, D(x): 0.50, D(G(z)): 0.50\n",
            "Epoch [8/15], Step [2200/2618], D_loss: 1.3207, G_loss: 0.7008, D(x): 0.53, D(G(z)): 0.50\n",
            "Epoch [8/15], Step [2300/2618], D_loss: 1.3704, G_loss: 0.7174, D(x): 0.50, D(G(z)): 0.49\n",
            "Epoch [8/15], Step [2400/2618], D_loss: 1.3905, G_loss: 0.7054, D(x): 0.50, D(G(z)): 0.50\n",
            "Epoch [8/15], Step [2500/2618], D_loss: 1.3691, G_loss: 0.7112, D(x): 0.51, D(G(z)): 0.50\n",
            "Epoch [8/15], Step [2600/2618], D_loss: 1.3807, G_loss: 0.7283, D(x): 0.48, D(G(z)): 0.47\n",
            "Epoch [9/15], Step [100/2618], D_loss: 1.4079, G_loss: 0.7048, D(x): 0.47, D(G(z)): 0.48\n",
            "Epoch [9/15], Step [200/2618], D_loss: 1.3961, G_loss: 0.6604, D(x): 0.53, D(G(z)): 0.53\n",
            "Epoch [9/15], Step [300/2618], D_loss: 1.3827, G_loss: 0.6591, D(x): 0.51, D(G(z)): 0.51\n",
            "Epoch [9/15], Step [400/2618], D_loss: 1.4087, G_loss: 0.7392, D(x): 0.47, D(G(z)): 0.48\n",
            "Epoch [9/15], Step [500/2618], D_loss: 1.3194, G_loss: 0.8207, D(x): 0.52, D(G(z)): 0.49\n",
            "Epoch [9/15], Step [600/2618], D_loss: 1.4135, G_loss: 0.7407, D(x): 0.45, D(G(z)): 0.46\n",
            "Epoch [9/15], Step [700/2618], D_loss: 1.3127, G_loss: 0.7644, D(x): 0.50, D(G(z)): 0.46\n",
            "Epoch [9/15], Step [800/2618], D_loss: 1.3325, G_loss: 0.7341, D(x): 0.49, D(G(z)): 0.46\n",
            "Epoch [9/15], Step [900/2618], D_loss: 1.3904, G_loss: 0.7046, D(x): 0.50, D(G(z)): 0.50\n",
            "Epoch [9/15], Step [1000/2618], D_loss: 1.4070, G_loss: 0.7101, D(x): 0.46, D(G(z)): 0.47\n",
            "Epoch [9/15], Step [1100/2618], D_loss: 1.3598, G_loss: 0.7029, D(x): 0.53, D(G(z)): 0.51\n",
            "Epoch [9/15], Step [1200/2618], D_loss: 1.3661, G_loss: 0.6672, D(x): 0.53, D(G(z)): 0.52\n",
            "Epoch [9/15], Step [1300/2618], D_loss: 1.3263, G_loss: 0.9022, D(x): 0.48, D(G(z)): 0.44\n",
            "Epoch [9/15], Step [1400/2618], D_loss: 1.3272, G_loss: 0.7111, D(x): 0.52, D(G(z)): 0.49\n",
            "Epoch [9/15], Step [1500/2618], D_loss: 1.4148, G_loss: 0.6956, D(x): 0.47, D(G(z)): 0.48\n",
            "Epoch [9/15], Step [1600/2618], D_loss: 1.3418, G_loss: 0.5942, D(x): 0.56, D(G(z)): 0.53\n",
            "Epoch [9/15], Step [1700/2618], D_loss: 1.3521, G_loss: 0.7110, D(x): 0.51, D(G(z)): 0.49\n",
            "Epoch [9/15], Step [1800/2618], D_loss: 1.3725, G_loss: 0.7158, D(x): 0.49, D(G(z)): 0.48\n",
            "Epoch [9/15], Step [1900/2618], D_loss: 1.3840, G_loss: 0.6912, D(x): 0.50, D(G(z)): 0.49\n",
            "Epoch [9/15], Step [2000/2618], D_loss: 1.4025, G_loss: 0.6741, D(x): 0.48, D(G(z)): 0.48\n",
            "Epoch [9/15], Step [2100/2618], D_loss: 1.3705, G_loss: 0.8709, D(x): 0.49, D(G(z)): 0.48\n",
            "Epoch [9/15], Step [2200/2618], D_loss: 1.3869, G_loss: 0.7140, D(x): 0.49, D(G(z)): 0.48\n",
            "Epoch [9/15], Step [2300/2618], D_loss: 1.3541, G_loss: 0.5967, D(x): 0.54, D(G(z)): 0.52\n",
            "Epoch [9/15], Step [2400/2618], D_loss: 1.3228, G_loss: 0.6939, D(x): 0.55, D(G(z)): 0.50\n",
            "Epoch [9/15], Step [2500/2618], D_loss: 1.3191, G_loss: 0.5883, D(x): 0.57, D(G(z)): 0.53\n",
            "Epoch [9/15], Step [2600/2618], D_loss: 1.4325, G_loss: 0.7947, D(x): 0.46, D(G(z)): 0.48\n",
            "Epoch [10/15], Step [100/2618], D_loss: 1.3718, G_loss: 0.6614, D(x): 0.53, D(G(z)): 0.52\n",
            "Epoch [10/15], Step [200/2618], D_loss: 1.4047, G_loss: 0.7018, D(x): 0.48, D(G(z)): 0.48\n",
            "Epoch [10/15], Step [300/2618], D_loss: 1.4310, G_loss: 0.6921, D(x): 0.51, D(G(z)): 0.53\n",
            "Epoch [10/15], Step [400/2618], D_loss: 1.3454, G_loss: 0.6642, D(x): 0.53, D(G(z)): 0.51\n",
            "Epoch [10/15], Step [500/2618], D_loss: 1.3796, G_loss: 0.6726, D(x): 0.48, D(G(z)): 0.48\n",
            "Epoch [10/15], Step [600/2618], D_loss: 1.4007, G_loss: 0.7104, D(x): 0.49, D(G(z)): 0.49\n",
            "Epoch [10/15], Step [700/2618], D_loss: 1.3930, G_loss: 0.7056, D(x): 0.52, D(G(z)): 0.51\n",
            "Epoch [10/15], Step [800/2618], D_loss: 1.3884, G_loss: 0.7498, D(x): 0.48, D(G(z)): 0.48\n",
            "Epoch [10/15], Step [900/2618], D_loss: 1.3946, G_loss: 0.7166, D(x): 0.49, D(G(z)): 0.48\n",
            "Epoch [10/15], Step [1000/2618], D_loss: 1.3911, G_loss: 0.7470, D(x): 0.48, D(G(z)): 0.48\n",
            "Epoch [10/15], Step [1100/2618], D_loss: 1.4758, G_loss: 0.6555, D(x): 0.45, D(G(z)): 0.48\n",
            "Epoch [10/15], Step [1200/2618], D_loss: 1.3910, G_loss: 0.6375, D(x): 0.52, D(G(z)): 0.52\n",
            "Epoch [10/15], Step [1300/2618], D_loss: 1.4021, G_loss: 0.5205, D(x): 0.58, D(G(z)): 0.58\n",
            "Epoch [10/15], Step [1400/2618], D_loss: 1.4171, G_loss: 0.7183, D(x): 0.49, D(G(z)): 0.50\n",
            "Epoch [10/15], Step [1500/2618], D_loss: 1.3620, G_loss: 0.6660, D(x): 0.52, D(G(z)): 0.51\n",
            "Epoch [10/15], Step [1600/2618], D_loss: 1.4012, G_loss: 0.8631, D(x): 0.46, D(G(z)): 0.46\n",
            "Epoch [10/15], Step [1700/2618], D_loss: 1.3611, G_loss: 0.7125, D(x): 0.50, D(G(z)): 0.48\n",
            "Epoch [10/15], Step [1800/2618], D_loss: 1.3940, G_loss: 0.7306, D(x): 0.50, D(G(z)): 0.50\n",
            "Epoch [10/15], Step [1900/2618], D_loss: 1.4059, G_loss: 0.7217, D(x): 0.46, D(G(z)): 0.47\n",
            "Epoch [10/15], Step [2000/2618], D_loss: 1.4137, G_loss: 0.7594, D(x): 0.47, D(G(z)): 0.48\n",
            "Epoch [10/15], Step [2100/2618], D_loss: 1.3819, G_loss: 0.7243, D(x): 0.50, D(G(z)): 0.50\n",
            "Epoch [10/15], Step [2200/2618], D_loss: 1.4239, G_loss: 0.7112, D(x): 0.51, D(G(z)): 0.52\n",
            "Epoch [10/15], Step [2300/2618], D_loss: 1.3520, G_loss: 0.6263, D(x): 0.54, D(G(z)): 0.51\n",
            "Epoch [10/15], Step [2400/2618], D_loss: 1.3322, G_loss: 0.7307, D(x): 0.54, D(G(z)): 0.51\n",
            "Epoch [10/15], Step [2500/2618], D_loss: 1.3525, G_loss: 0.7518, D(x): 0.51, D(G(z)): 0.49\n",
            "Epoch [10/15], Step [2600/2618], D_loss: 1.4984, G_loss: 0.7332, D(x): 0.44, D(G(z)): 0.49\n",
            "Epoch [11/15], Step [100/2618], D_loss: 1.3624, G_loss: 0.7458, D(x): 0.49, D(G(z)): 0.48\n",
            "Epoch [11/15], Step [200/2618], D_loss: 1.3699, G_loss: 0.7063, D(x): 0.49, D(G(z)): 0.48\n",
            "Epoch [11/15], Step [300/2618], D_loss: 1.3734, G_loss: 0.6581, D(x): 0.50, D(G(z)): 0.49\n",
            "Epoch [11/15], Step [400/2618], D_loss: 1.3752, G_loss: 0.6935, D(x): 0.49, D(G(z)): 0.49\n",
            "Epoch [11/15], Step [500/2618], D_loss: 1.3884, G_loss: 0.6482, D(x): 0.53, D(G(z)): 0.52\n",
            "Epoch [11/15], Step [600/2618], D_loss: 1.3805, G_loss: 0.7851, D(x): 0.47, D(G(z)): 0.46\n",
            "Epoch [11/15], Step [700/2618], D_loss: 1.3626, G_loss: 0.6760, D(x): 0.51, D(G(z)): 0.50\n",
            "Epoch [11/15], Step [800/2618], D_loss: 1.4409, G_loss: 0.7300, D(x): 0.50, D(G(z)): 0.52\n",
            "Epoch [11/15], Step [900/2618], D_loss: 1.3936, G_loss: 0.7121, D(x): 0.54, D(G(z)): 0.54\n",
            "Epoch [11/15], Step [1000/2618], D_loss: 1.3645, G_loss: 0.7619, D(x): 0.50, D(G(z)): 0.49\n",
            "Epoch [11/15], Step [1100/2618], D_loss: 1.4430, G_loss: 0.7671, D(x): 0.48, D(G(z)): 0.51\n",
            "Epoch [11/15], Step [1200/2618], D_loss: 1.3296, G_loss: 0.6786, D(x): 0.54, D(G(z)): 0.50\n",
            "Epoch [11/15], Step [1300/2618], D_loss: 1.3428, G_loss: 0.7321, D(x): 0.49, D(G(z)): 0.47\n",
            "Epoch [11/15], Step [1400/2618], D_loss: 1.3795, G_loss: 0.7090, D(x): 0.49, D(G(z)): 0.49\n",
            "Epoch [11/15], Step [1500/2618], D_loss: 1.4323, G_loss: 0.8142, D(x): 0.46, D(G(z)): 0.48\n",
            "Epoch [11/15], Step [1600/2618], D_loss: 1.3825, G_loss: 0.6098, D(x): 0.51, D(G(z)): 0.51\n",
            "Epoch [11/15], Step [1700/2618], D_loss: 1.2830, G_loss: 0.6034, D(x): 0.56, D(G(z)): 0.50\n",
            "Epoch [11/15], Step [1800/2618], D_loss: 1.3375, G_loss: 0.7571, D(x): 0.50, D(G(z)): 0.47\n",
            "Epoch [11/15], Step [1900/2618], D_loss: 1.3904, G_loss: 0.7544, D(x): 0.46, D(G(z)): 0.46\n",
            "Epoch [11/15], Step [2000/2618], D_loss: 1.3582, G_loss: 0.7377, D(x): 0.49, D(G(z)): 0.47\n",
            "Epoch [11/15], Step [2100/2618], D_loss: 1.3477, G_loss: 0.7496, D(x): 0.50, D(G(z)): 0.48\n",
            "Epoch [11/15], Step [2200/2618], D_loss: 1.3769, G_loss: 0.6672, D(x): 0.52, D(G(z)): 0.51\n",
            "Epoch [11/15], Step [2300/2618], D_loss: 1.3911, G_loss: 0.7086, D(x): 0.50, D(G(z)): 0.50\n",
            "Epoch [11/15], Step [2400/2618], D_loss: 1.4148, G_loss: 0.7506, D(x): 0.46, D(G(z)): 0.47\n",
            "Epoch [11/15], Step [2500/2618], D_loss: 1.4216, G_loss: 0.6920, D(x): 0.47, D(G(z)): 0.48\n",
            "Epoch [11/15], Step [2600/2618], D_loss: 1.3385, G_loss: 0.6723, D(x): 0.53, D(G(z)): 0.51\n",
            "Epoch [12/15], Step [100/2618], D_loss: 1.3217, G_loss: 0.6642, D(x): 0.52, D(G(z)): 0.49\n",
            "Epoch [12/15], Step [200/2618], D_loss: 1.3573, G_loss: 0.6848, D(x): 0.51, D(G(z)): 0.49\n",
            "Epoch [12/15], Step [300/2618], D_loss: 1.3501, G_loss: 0.7014, D(x): 0.53, D(G(z)): 0.51\n",
            "Epoch [12/15], Step [400/2618], D_loss: 1.3243, G_loss: 0.6563, D(x): 0.50, D(G(z)): 0.46\n",
            "Epoch [12/15], Step [500/2618], D_loss: 1.4061, G_loss: 0.5977, D(x): 0.52, D(G(z)): 0.52\n",
            "Epoch [12/15], Step [600/2618], D_loss: 1.4729, G_loss: 0.7035, D(x): 0.52, D(G(z)): 0.55\n",
            "Epoch [12/15], Step [700/2618], D_loss: 1.4276, G_loss: 0.6295, D(x): 0.51, D(G(z)): 0.53\n",
            "Epoch [12/15], Step [800/2618], D_loss: 1.4258, G_loss: 0.7811, D(x): 0.45, D(G(z)): 0.46\n",
            "Epoch [12/15], Step [900/2618], D_loss: 1.3836, G_loss: 0.7061, D(x): 0.49, D(G(z)): 0.49\n",
            "Epoch [12/15], Step [1000/2618], D_loss: 1.3908, G_loss: 0.7121, D(x): 0.51, D(G(z)): 0.51\n",
            "Epoch [12/15], Step [1100/2618], D_loss: 1.3745, G_loss: 0.6965, D(x): 0.51, D(G(z)): 0.50\n",
            "Epoch [12/15], Step [1200/2618], D_loss: 1.3856, G_loss: 0.6721, D(x): 0.49, D(G(z)): 0.48\n",
            "Epoch [12/15], Step [1300/2618], D_loss: 1.3748, G_loss: 0.7281, D(x): 0.49, D(G(z)): 0.48\n",
            "Epoch [12/15], Step [1400/2618], D_loss: 1.3372, G_loss: 0.6371, D(x): 0.54, D(G(z)): 0.51\n",
            "Epoch [12/15], Step [1500/2618], D_loss: 1.3778, G_loss: 0.7588, D(x): 0.48, D(G(z)): 0.47\n",
            "Epoch [12/15], Step [1600/2618], D_loss: 1.3971, G_loss: 0.7274, D(x): 0.48, D(G(z)): 0.49\n",
            "Epoch [12/15], Step [1700/2618], D_loss: 1.4314, G_loss: 0.7361, D(x): 0.48, D(G(z)): 0.50\n",
            "Epoch [12/15], Step [1800/2618], D_loss: 1.3435, G_loss: 0.6526, D(x): 0.52, D(G(z)): 0.50\n",
            "Epoch [12/15], Step [1900/2618], D_loss: 1.4129, G_loss: 0.7319, D(x): 0.51, D(G(z)): 0.52\n",
            "Epoch [12/15], Step [2000/2618], D_loss: 1.4059, G_loss: 0.7176, D(x): 0.48, D(G(z)): 0.49\n",
            "Epoch [12/15], Step [2100/2618], D_loss: 1.3660, G_loss: 0.7076, D(x): 0.50, D(G(z)): 0.48\n",
            "Epoch [12/15], Step [2200/2618], D_loss: 1.3204, G_loss: 0.6965, D(x): 0.54, D(G(z)): 0.50\n",
            "Epoch [12/15], Step [2300/2618], D_loss: 1.3573, G_loss: 0.6566, D(x): 0.51, D(G(z)): 0.49\n",
            "Epoch [12/15], Step [2400/2618], D_loss: 1.3797, G_loss: 0.7157, D(x): 0.52, D(G(z)): 0.51\n",
            "Epoch [12/15], Step [2500/2618], D_loss: 1.4096, G_loss: 0.6954, D(x): 0.50, D(G(z)): 0.51\n",
            "Epoch [12/15], Step [2600/2618], D_loss: 1.3713, G_loss: 0.7327, D(x): 0.51, D(G(z)): 0.50\n",
            "Epoch [13/15], Step [100/2618], D_loss: 1.4149, G_loss: 0.7742, D(x): 0.48, D(G(z)): 0.49\n",
            "Epoch [13/15], Step [200/2618], D_loss: 1.3496, G_loss: 0.7048, D(x): 0.51, D(G(z)): 0.49\n",
            "Epoch [13/15], Step [300/2618], D_loss: 1.3585, G_loss: 0.6834, D(x): 0.50, D(G(z)): 0.49\n",
            "Epoch [13/15], Step [400/2618], D_loss: 1.3995, G_loss: 0.7253, D(x): 0.50, D(G(z)): 0.51\n",
            "Epoch [13/15], Step [500/2618], D_loss: 1.4023, G_loss: 0.6993, D(x): 0.48, D(G(z)): 0.49\n",
            "Epoch [13/15], Step [600/2618], D_loss: 1.4066, G_loss: 0.6890, D(x): 0.48, D(G(z)): 0.49\n",
            "Epoch [13/15], Step [700/2618], D_loss: 1.4295, G_loss: 0.6509, D(x): 0.49, D(G(z)): 0.51\n",
            "Epoch [13/15], Step [800/2618], D_loss: 1.4636, G_loss: 0.7345, D(x): 0.48, D(G(z)): 0.51\n",
            "Epoch [13/15], Step [900/2618], D_loss: 1.3866, G_loss: 0.6856, D(x): 0.49, D(G(z)): 0.49\n",
            "Epoch [13/15], Step [1000/2618], D_loss: 1.3577, G_loss: 0.6989, D(x): 0.54, D(G(z)): 0.52\n",
            "Epoch [13/15], Step [1100/2618], D_loss: 1.4206, G_loss: 0.7594, D(x): 0.47, D(G(z)): 0.48\n",
            "Epoch [13/15], Step [1200/2618], D_loss: 1.3679, G_loss: 0.6758, D(x): 0.49, D(G(z)): 0.48\n",
            "Epoch [13/15], Step [1300/2618], D_loss: 1.3650, G_loss: 0.7245, D(x): 0.50, D(G(z)): 0.49\n",
            "Epoch [13/15], Step [1400/2618], D_loss: 1.4146, G_loss: 0.6323, D(x): 0.52, D(G(z)): 0.53\n",
            "Epoch [13/15], Step [1500/2618], D_loss: 1.3497, G_loss: 0.7491, D(x): 0.50, D(G(z)): 0.48\n",
            "Epoch [13/15], Step [1600/2618], D_loss: 1.3234, G_loss: 0.7018, D(x): 0.49, D(G(z)): 0.45\n",
            "Epoch [13/15], Step [1700/2618], D_loss: 1.3744, G_loss: 0.7269, D(x): 0.48, D(G(z)): 0.47\n",
            "Epoch [13/15], Step [1800/2618], D_loss: 1.4228, G_loss: 0.7043, D(x): 0.45, D(G(z)): 0.47\n",
            "Epoch [13/15], Step [1900/2618], D_loss: 1.3819, G_loss: 0.6801, D(x): 0.51, D(G(z)): 0.50\n",
            "Epoch [13/15], Step [2000/2618], D_loss: 1.5103, G_loss: 0.7276, D(x): 0.47, D(G(z)): 0.53\n",
            "Epoch [13/15], Step [2100/2618], D_loss: 1.3625, G_loss: 0.6350, D(x): 0.52, D(G(z)): 0.51\n",
            "Epoch [13/15], Step [2200/2618], D_loss: 1.4455, G_loss: 0.6422, D(x): 0.49, D(G(z)): 0.52\n",
            "Epoch [13/15], Step [2300/2618], D_loss: 1.3146, G_loss: 0.8220, D(x): 0.51, D(G(z)): 0.47\n",
            "Epoch [13/15], Step [2400/2618], D_loss: 1.2857, G_loss: 0.7132, D(x): 0.49, D(G(z)): 0.44\n",
            "Epoch [13/15], Step [2500/2618], D_loss: 1.3764, G_loss: 0.6591, D(x): 0.52, D(G(z)): 0.52\n",
            "Epoch [13/15], Step [2600/2618], D_loss: 1.4244, G_loss: 0.7379, D(x): 0.50, D(G(z)): 0.51\n",
            "Epoch [14/15], Step [100/2618], D_loss: 1.3899, G_loss: 0.7536, D(x): 0.46, D(G(z)): 0.46\n",
            "Epoch [14/15], Step [200/2618], D_loss: 1.3966, G_loss: 0.6695, D(x): 0.51, D(G(z)): 0.52\n",
            "Epoch [14/15], Step [300/2618], D_loss: 1.4021, G_loss: 0.7060, D(x): 0.51, D(G(z)): 0.51\n",
            "Epoch [14/15], Step [400/2618], D_loss: 1.4345, G_loss: 0.6691, D(x): 0.52, D(G(z)): 0.54\n",
            "Epoch [14/15], Step [500/2618], D_loss: 1.3559, G_loss: 0.6988, D(x): 0.51, D(G(z)): 0.49\n",
            "Epoch [14/15], Step [600/2618], D_loss: 1.3626, G_loss: 0.6327, D(x): 0.53, D(G(z)): 0.52\n",
            "Epoch [14/15], Step [700/2618], D_loss: 1.4117, G_loss: 0.7765, D(x): 0.49, D(G(z)): 0.50\n",
            "Epoch [14/15], Step [800/2618], D_loss: 1.3540, G_loss: 0.7959, D(x): 0.50, D(G(z)): 0.48\n",
            "Epoch [14/15], Step [900/2618], D_loss: 1.3653, G_loss: 0.7105, D(x): 0.52, D(G(z)): 0.51\n",
            "Epoch [14/15], Step [1000/2618], D_loss: 1.3915, G_loss: 0.7753, D(x): 0.46, D(G(z)): 0.46\n",
            "Epoch [14/15], Step [1100/2618], D_loss: 1.3828, G_loss: 0.6582, D(x): 0.51, D(G(z)): 0.50\n",
            "Epoch [14/15], Step [1200/2618], D_loss: 1.4058, G_loss: 0.7059, D(x): 0.50, D(G(z)): 0.51\n",
            "Epoch [14/15], Step [1300/2618], D_loss: 1.3850, G_loss: 0.8048, D(x): 0.45, D(G(z)): 0.45\n",
            "Epoch [14/15], Step [1400/2618], D_loss: 1.3813, G_loss: 0.6554, D(x): 0.57, D(G(z)): 0.55\n",
            "Epoch [14/15], Step [1500/2618], D_loss: 1.3728, G_loss: 0.6731, D(x): 0.51, D(G(z)): 0.50\n",
            "Epoch [14/15], Step [1600/2618], D_loss: 1.4037, G_loss: 0.7476, D(x): 0.47, D(G(z)): 0.47\n",
            "Epoch [14/15], Step [1700/2618], D_loss: 1.3519, G_loss: 0.7317, D(x): 0.51, D(G(z)): 0.49\n",
            "Epoch [14/15], Step [1800/2618], D_loss: 1.4039, G_loss: 0.6531, D(x): 0.50, D(G(z)): 0.50\n",
            "Epoch [14/15], Step [1900/2618], D_loss: 1.3843, G_loss: 0.7046, D(x): 0.50, D(G(z)): 0.50\n",
            "Epoch [14/15], Step [2000/2618], D_loss: 1.3803, G_loss: 0.7516, D(x): 0.47, D(G(z)): 0.46\n",
            "Epoch [14/15], Step [2100/2618], D_loss: 1.3655, G_loss: 0.7095, D(x): 0.50, D(G(z)): 0.49\n",
            "Epoch [14/15], Step [2200/2618], D_loss: 1.4010, G_loss: 0.8378, D(x): 0.50, D(G(z)): 0.51\n",
            "Epoch [14/15], Step [2300/2618], D_loss: 1.4750, G_loss: 0.6580, D(x): 0.56, D(G(z)): 0.58\n",
            "Epoch [14/15], Step [2400/2618], D_loss: 1.4388, G_loss: 0.7434, D(x): 0.48, D(G(z)): 0.50\n",
            "Epoch [14/15], Step [2500/2618], D_loss: 1.4446, G_loss: 0.7646, D(x): 0.46, D(G(z)): 0.48\n",
            "Epoch [14/15], Step [2600/2618], D_loss: 1.4033, G_loss: 0.6699, D(x): 0.50, D(G(z)): 0.51\n",
            "Epoch [15/15], Step [100/2618], D_loss: 1.3801, G_loss: 0.7163, D(x): 0.49, D(G(z)): 0.49\n",
            "Epoch [15/15], Step [200/2618], D_loss: 1.3607, G_loss: 0.7911, D(x): 0.49, D(G(z)): 0.48\n",
            "Epoch [15/15], Step [300/2618], D_loss: 1.3825, G_loss: 0.6596, D(x): 0.54, D(G(z)): 0.53\n",
            "Epoch [15/15], Step [400/2618], D_loss: 1.3937, G_loss: 0.7598, D(x): 0.49, D(G(z)): 0.49\n",
            "Epoch [15/15], Step [500/2618], D_loss: 1.3493, G_loss: 0.6973, D(x): 0.53, D(G(z)): 0.51\n",
            "Epoch [15/15], Step [600/2618], D_loss: 1.3616, G_loss: 0.6345, D(x): 0.54, D(G(z)): 0.52\n",
            "Epoch [15/15], Step [700/2618], D_loss: 1.4252, G_loss: 0.6311, D(x): 0.51, D(G(z)): 0.53\n",
            "Epoch [15/15], Step [800/2618], D_loss: 1.3882, G_loss: 0.6535, D(x): 0.53, D(G(z)): 0.52\n",
            "Epoch [15/15], Step [900/2618], D_loss: 1.3946, G_loss: 0.7497, D(x): 0.50, D(G(z)): 0.50\n",
            "Epoch [15/15], Step [1000/2618], D_loss: 1.3786, G_loss: 0.6533, D(x): 0.54, D(G(z)): 0.53\n",
            "Epoch [15/15], Step [1100/2618], D_loss: 1.3837, G_loss: 0.7950, D(x): 0.46, D(G(z)): 0.46\n",
            "Epoch [15/15], Step [1200/2618], D_loss: 1.3739, G_loss: 0.7472, D(x): 0.46, D(G(z)): 0.44\n",
            "Epoch [15/15], Step [1300/2618], D_loss: 1.4119, G_loss: 0.6925, D(x): 0.50, D(G(z)): 0.51\n",
            "Epoch [15/15], Step [1400/2618], D_loss: 1.3980, G_loss: 0.7076, D(x): 0.52, D(G(z)): 0.52\n",
            "Epoch [15/15], Step [1500/2618], D_loss: 1.3609, G_loss: 0.6980, D(x): 0.50, D(G(z)): 0.48\n",
            "Epoch [15/15], Step [1600/2618], D_loss: 1.3638, G_loss: 0.8064, D(x): 0.46, D(G(z)): 0.45\n",
            "Epoch [15/15], Step [1700/2618], D_loss: 1.3507, G_loss: 0.7308, D(x): 0.50, D(G(z)): 0.48\n",
            "Epoch [15/15], Step [1800/2618], D_loss: 1.3771, G_loss: 0.6942, D(x): 0.53, D(G(z)): 0.52\n",
            "Epoch [15/15], Step [1900/2618], D_loss: 1.5228, G_loss: 0.6838, D(x): 0.43, D(G(z)): 0.49\n",
            "Epoch [15/15], Step [2000/2618], D_loss: 1.3405, G_loss: 0.8057, D(x): 0.49, D(G(z)): 0.47\n",
            "Epoch [15/15], Step [2100/2618], D_loss: 1.3306, G_loss: 0.6584, D(x): 0.54, D(G(z)): 0.51\n",
            "Epoch [15/15], Step [2200/2618], D_loss: 1.4418, G_loss: 0.7763, D(x): 0.46, D(G(z)): 0.48\n",
            "Epoch [15/15], Step [2300/2618], D_loss: 1.4604, G_loss: 0.7513, D(x): 0.46, D(G(z)): 0.50\n",
            "Epoch [15/15], Step [2400/2618], D_loss: 1.4059, G_loss: 0.6882, D(x): 0.52, D(G(z)): 0.53\n",
            "Epoch [15/15], Step [2500/2618], D_loss: 1.4167, G_loss: 0.7602, D(x): 0.48, D(G(z)): 0.49\n",
            "Epoch [15/15], Step [2600/2618], D_loss: 1.3466, G_loss: 0.7534, D(x): 0.48, D(G(z)): 0.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate fake image\n",
        "z = torch.randn(1, latent_dim)\n",
        "fake_image = G(z)\n",
        "fake_image = fake_images.view(fake_images.size(0), 3, 32, 32)\n",
        "fake_image = (fake_images + 1) / 2  # Rescale images to [0, 1]\n",
        "fake_image = fake_image.detach().numpy().reshape(32,32,3)\n",
        "plt.imshow(fake_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "fwAxevKYERfP",
        "outputId": "6a61c214-ccd5-4178-8e9c-df1bf6a0b091"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 32, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Plot the fake images\\nimport matplotlib.pyplot as plt\\n\\nfig, axes = plt.subplots(1, 16, figsize=(15, 15))\\nfor ax, img in zip(axes.flatten(), fake_images):\\n    ax.axis('off')\\n    ax.set_adjustable('box')\\n    img = transforms.ToPILImage()(img.cpu().squeeze())\\n    ax.imshow(img)\\nplt.show()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The GAN does not generate a meaningful image. This may be due to undertraining due to runtime constraints."
      ],
      "metadata": {
        "id": "Hn3FMivOhRE0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kalantar, R. (2023, November 22). Variational auto-encoder (VAE)-pytorch tutorial. Medium. https://medium.com/@rekalantar/variational-auto-encoder-vae-pytorch-tutorial-dce2d2fe0f5f\n",
        "\n",
        "The Programming Geek. (2024b, January 29). Generating new realities: Crafting a simple gan with pytorch. Medium. https://medium.com/@theprogramminggeek/generating-new-realities-crafting-a-simple-gan-with-pytorch-fc312f57a12d\n",
        "\n"
      ],
      "metadata": {
        "id": "DCNzFNINHUFE"
      }
    }
  ]
}